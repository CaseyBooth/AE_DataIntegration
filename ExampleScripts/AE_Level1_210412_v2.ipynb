{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/booth.c.1/OneDrive - Procter and Gamble/Code/SprayBit/AE Dev v3/CalFiles/CalData_VH23.csv\n"
     ]
    }
   ],
   "source": [
    "# set calibration file\n",
    "# choose it through file dialog\n",
    "\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "import os\n",
    "from AESprayBitUtil import *\n",
    "# print(os.path.basename(your_path))\n",
    "#-----switched to dialog window\n",
    "\n",
    "\n",
    "# extension = '.csv'\n",
    "# old_board=False    #set this value to config for the 2 different formats; old board, new board\n",
    "\n",
    "root = tk.Tk()  # file selection window\n",
    "\n",
    "#Open the data file\n",
    "caljoinedfilename = askopenfilename(title=\"Select Calibration file for consumption\") # show an \"Open\" dialog box and return the path to the selected file\n",
    "root.destroy()\n",
    "# filename=os.path.basename(filename1)\n",
    "# filename=filename[:-4]\n",
    "\n",
    "print(caljoinedfilename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/booth.c.1/OneDrive - Procter and Gamble/Code/SprayBit/AE Dev v3/RawData/Month1/CC/CC-147.csv\n",
      "C:\\Users\\booth.c.1\\OneDrive - Procter and Gamble\\Code\\SprayBit\\AE Dev v3\\RawData\\Month1\\CC\n"
     ]
    }
   ],
   "source": [
    "#  set data input and output locations\n",
    "#   this assumes there are multiple folders in the overall rawdata directory\n",
    "#    one for each leg of the study\n",
    "\n",
    "\n",
    "root = tk.Tk()  # file selection window\n",
    "\n",
    "#Open a data file\n",
    "# show an \"Open\" dialog box and return the path to the selected file\n",
    "dataDir = askopenfilename(title=\"Select any file from a raw data folder\")\n",
    "root.destroy() # close Tk\n",
    "# filename=os.path.basename(filename1)\n",
    "# filename=filename[:-4]\n",
    "\n",
    "print(dataDir)\n",
    "# go up a level to folder location of all the raw data files\n",
    "dataDir=os.path.dirname(os.path.abspath(dataDir))\n",
    "print(dataDir)\n",
    "# go up another level to folder location of all raw data folders\n",
    "# dataDir=os.path.dirname(os.path.abspath(dataDir))\n",
    "# print(dataDir)\n",
    "\n",
    "\n",
    "# #below should be handeled when pulling in all data in main analysis\n",
    "\n",
    "# resultDirChart = dataDir+'\\ResultCharts/'    #set where to place charts\n",
    "# resultDirXL = dataDir+'\\Result_xl/'    #set where to place preprocessed results \n",
    "\n",
    "# #confirm if chart and xl folders exist;  create folders if not\n",
    "# if not os.path.exists(resultDirChart):\n",
    "#     os.makedirs(resultDirChart)\n",
    "    \n",
    "# if not os.path.exists(resultDirXL):\n",
    "#     os.makedirs(resultDirXL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/booth.c.1/OneDrive - Procter and Gamble/Code/SprayBit/AE Dev v3/CalFiles/CalData_VH23.csv\n"
     ]
    }
   ],
   "source": [
    "#  Setup:  Set Summary file name to contain key attributes for each raw data file\n",
    "#          set study time point to define for multi leg analysis\n",
    "#          verify format of raw data ;old or new firmware --2 or 4 lines of cal info\n",
    "#          set files are csv or not\n",
    "#          set number of characters used to identify the leg ID\n",
    "\n",
    "\n",
    "Summaryfilename = 'AE_BigBang3_M1_'\n",
    "studyTimeID ='Month 1'\n",
    "legChars = 2   # number of characters starting from left of string in the leg id of the filename\n",
    "\n",
    "#  csv file to translate between filenames and panelist names\n",
    "userNameFile = 'userCodeToName.csv'\n",
    "\n",
    "old_board=False    #set this value to config for the 2 different formats; old firmware, new firmware\n",
    "debug=True  # determine if print out updates as progress through the code\n",
    "csvFormat=True  #set if files not saved as csv;  will also need to update folder names below to remove from file list\n",
    "removeFolders = ['Resultb','Error']  #folder to remove that are in same directory as raw data if not in csv format\n",
    "strokeLimit = 1000   # number of peaks over which to consider an error;  will end program to inspect plot\n",
    "                        #can take significant time to process so many peaks\n",
    "    \n",
    "    \n",
    "dataStartMin=0.5  # length of time in minutes prior to stroke to gather motion data for shake behavior\n",
    "accelThresh = 1000  #threshold of acceleration to consider a shaking event\n",
    "useTimeMin = 10/60    # length of time in minutes prior to stroke to gather motion data for movement\n",
    "occasionTimeMin = 60/60    # length of time in minutes prior to stroke to gather motion data for movement\n",
    "idleTimeToDefineUse = 6  #seconds of idle to be new usage\n",
    "\n",
    "requiresTimeShift = True  #is there a need to shift the timestamp (for daylight savings?)\n",
    "timeShiftMins = 60   #minutes to shift time (negative value acceptable)\n",
    "\n",
    "if not csvFormat:\n",
    "    print('will remove:  ', removeFolders)\n",
    "\n",
    "\n",
    "calextension = '.csv'\n",
    "# caljoinedfilename = calfilename+calextension\n",
    "\n",
    "print(caljoinedfilename)\n",
    "\n",
    "# ***********Set dates for beginning / end of study to elimate non-user data--not used at this time;\n",
    "# first_time = pd.to_datetime('2010-06-10')\n",
    "# first_time = pd.to_datetime('2019-06-18')\n",
    "# print(first_time)\n",
    "# second_time = pd.to_datetime('2030-07-14')\n",
    "# second_time = pd.to_datetime('2019-07-18')\n",
    "# print(second_time)\n",
    "\n",
    "#get translation from filename code to username\n",
    "# dfUserNames = formatUserName(userNameFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T01:57:09.351973Z",
     "start_time": "2019-05-24T01:57:09.347424Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #A check step to \n",
    "# #  1  go through all folders in study to confirm setup is correctly finding all files\n",
    "# #  2  create and/or verify the data ouput folders exist \n",
    "# #     each leg folder will get 2 folders added for holding the chart and excel outputs \n",
    "\n",
    "\n",
    "# #---------------------------\n",
    "# #handle if files were not saved in csv based on boolean defined above in setup\n",
    "# legFolders=[f for f in os.listdir(dataDir)]\n",
    "# files=[]\n",
    "\n",
    "# for folderID in legFolders:\n",
    "#     print(folderID)\n",
    "#     dataLocation = dataDir + \"/\" + folderID + \"/\"    \n",
    "#     resultDirChart = dataLocation +'ResultCharts/'    #set where to place charts\n",
    "#     resultDirXL = dataLocation +'Result_xl/'    #set where to place processed excel results \n",
    "\n",
    "#     if not os.path.exists(resultDirChart):\n",
    "#         os.makedirs(resultDirChart)\n",
    "#     if not os.path.exists(resultDirXL):\n",
    "#         os.makedirs(resultDirXL)\n",
    "        \n",
    "#     if csvFormat:\n",
    "#         filesA = [f for f in os.listdir(dataLocation) if f.endswith('.' + 'csv')]\n",
    "#     else:\n",
    "#         filesA = [f for f in os.listdir(dataLocation)]  #****  if files are not in .csv then no other files can be in directory\n",
    "\n",
    "#     # remove folders from file list if not in csv format \n",
    "#     if not csvFormat:\n",
    "#         for x in removeFolders:        \n",
    "#             filesA.remove(x)\n",
    "#     #         filesA.remove('Resultb')\n",
    "#     #         filesA.remove('Error')\n",
    "\n",
    "#     if csvFormat:\n",
    "#         filesB = [x[:-4] for x in filesA]   #remove extension so result files are named cleanly\n",
    "#     else:\n",
    "#         filesB = filesA   # no need to modify if not saved as csv\n",
    "#     files=files+filesB\n",
    "\n",
    "\n",
    "# #---------------------------\n",
    "#     #select if files end in csv\n",
    "# if csvFormat:\n",
    "#     extension='.csv'\n",
    "# else:\n",
    "#     extension=''\n",
    "\n",
    "# # *******use below to remove calibration file if it is in the same directory as raw data, not needed if using subfolder\n",
    "# # filesA.remove(caljoinedfilename)\n",
    "\n",
    "\n",
    "\n",
    "# print(dataLocation)\n",
    "# print(resultDirChart)\n",
    "# print(resultDirXL)\n",
    "# print(files)\n",
    "# print(caljoinedfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T01:57:09.351973Z",
     "start_time": "2019-05-24T01:57:09.347424Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booth.c.1\\OneDrive - Procter and Gamble\\Code\\SprayBit\\AE Dev v3\\RawData\\Month1\\CC/\n",
      "C:\\Users\\booth.c.1\\OneDrive - Procter and Gamble\\Code\\SprayBit\\AE Dev v3\\RawData\\Month1\\CC/ResultCharts/\n",
      "C:\\Users\\booth.c.1\\OneDrive - Procter and Gamble\\Code\\SprayBit\\AE Dev v3\\RawData\\Month1\\CC/Result_xl/\n",
      "['CC-146', 'CC-147', 'CC-148', 'CC-149', 'CC-150', 'CC-151', 'CC-152', 'CC-153', 'CC-154', 'CC-155', 'CC-156', 'CC-157', 'CC-158', 'CC-159', 'CC-160']\n",
      "C:/Users/booth.c.1/OneDrive - Procter and Gamble/Code/SprayBit/AE Dev v3/CalFiles/CalData_VH23.csv\n"
     ]
    }
   ],
   "source": [
    "#A check step to \n",
    "#  1  go through all files in 1 folder of study to confirm setup is correctly finding all files\n",
    "#  2  create and/or verify the data ouput folders exist \n",
    "#     each leg folder will get 2 folders added for holding the chart and excel outputs \n",
    "\n",
    "\n",
    "#---------------------------\n",
    "#handle if files were not saved in csv based on boolean defined above in setup\n",
    "files=[]\n",
    "\n",
    "dataLocation = dataDir + \"/\"     \n",
    "resultDirChart = dataLocation +'ResultCharts/'    #set where to place charts\n",
    "resultDirXL = dataLocation +'Result_xl/'    #set where to place processed excel results \n",
    "\n",
    "if not os.path.exists(resultDirChart):\n",
    "    os.makedirs(resultDirChart)\n",
    "if not os.path.exists(resultDirXL):\n",
    "    os.makedirs(resultDirXL)\n",
    "\n",
    "if csvFormat:\n",
    "    filesA = [f for f in os.listdir(dataLocation) if f.endswith('.' + 'csv')]\n",
    "else:\n",
    "    filesA = [f for f in os.listdir(dataLocation)]  #****  if files are not in .csv then no other files can be in directory\n",
    "\n",
    "# remove folders from file list if not in csv format \n",
    "if not csvFormat:\n",
    "    for x in removeFolders:        \n",
    "        filesA.remove(x)\n",
    "#         filesA.remove('Resultb')\n",
    "#         filesA.remove('Error')\n",
    "\n",
    "if csvFormat:\n",
    "    filesB = [x[:-4] for x in filesA]   #remove extension so result files are named cleanly\n",
    "else:\n",
    "    filesB = filesA   # no need to modify if not saved as csv\n",
    "files=filesB\n",
    "\n",
    "\n",
    "#---------------------------\n",
    "    #select if files end in csv\n",
    "if csvFormat:\n",
    "    extension='.csv'\n",
    "else:\n",
    "    extension=''\n",
    "\n",
    "# *******use below to remove calibration file if it is in the same directory as raw data, not needed if using subfolder\n",
    "# filesA.remove(caljoinedfilename)\n",
    "\n",
    "\n",
    "\n",
    "print(dataLocation)\n",
    "print(resultDirChart)\n",
    "print(resultDirXL)\n",
    "print(files)\n",
    "print(caljoinedfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load librarys\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "# %matplotlib inline\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "from pylab import text\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import timeit\n",
    "import numpy.polynomial.polynomial as poly\n",
    "from detect_peaks import detect_peaks #import detect_peaks.py (you need the file in same directory)\n",
    "from pandas import ExcelWriter #Import excel file library\n",
    "import statistics\n",
    "\n",
    "#for date time converter\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "import plotly.express as px\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Main Analysis Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T02:43:30.512811Z",
     "start_time": "2019-05-24T02:43:10.027069Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CC-146', 'CC-147', 'CC-148', 'CC-149', 'CC-150', 'CC-151', 'CC-152', 'CC-153', 'CC-154', 'CC-155', 'CC-156', 'CC-157', 'CC-158', 'CC-159', 'CC-160']\n",
      "generating dataframes for  CC-146\n",
      "Found  0  garbage lines\n",
      "calculating Data Rate for  CC-146\n",
      "start time was  2021-03-22 07:15:31.019000\n",
      "start time is now  2021-03-22 08:15:31.019000\n",
      "average data rate =  104.41409595445975\n",
      "Clean, filter and plot initial data  CC-146\n",
      "Cal value =  0.49963\n",
      "vhallMax =  0.46959966027266015\n",
      "setpoint =  0.11739991506816504\n",
      "creating raw data plot\n",
      "detecting peaks for  CC-146\n",
      "290  peaks\n",
      "2787  valleys\n",
      "eliminate multiple peaks for  CC-146\n",
      "setpoint 0.11739991506816504\n",
      "peaks to start 290\n",
      "peaks at end 20\n",
      "creating peak indexes for  CC-146\n",
      "time so far  3.3811159999999987\n",
      "ShakeThresh =  1000, useTimeThresh =  0.16666666666666666, occasionTimeThresh =  1.0\n",
      "5919, 17864, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booth.c.1\\OneDrive - Procter and Gamble\\Code\\SprayBit\\AE Dev v3\\AESprayBitUtil.py:292: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\booth.c.1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:299: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18163, 20446, 22527, 27153, 27737, 28000, 28895, 29383, 33549, 36042, 57143, 61438, 68130, 69630, 70293, 70695, 71396, 76688, data pts with neg data rate  0\n",
      "completed peak finding\n",
      "time for file so far  12.062394900000001\n",
      "defining spray direction for  CC-146\n",
      "setting day boundaries for  CC-146\n",
      "defining mass and angle for  CC-146\n",
      "creating excel for  CC-146\n",
      "Completed   CC-146\n",
      "\n",
      "time for this file  13.352239000000004\n",
      "\n",
      "generating dataframes for  CC-147\n",
      "Found  0  garbage lines\n",
      "calculating Data Rate for  CC-147\n",
      "start time was  2021-03-20 12:50:33.019000\n",
      "start time is now  2021-03-20 13:50:33.019000\n",
      "average data rate =  105.56014595102482\n",
      "Clean, filter and plot initial data  CC-147\n",
      "Cal value =  0.44645\n",
      "vhallMax =  0.34562983995710456\n",
      "setpoint =  0.08640745998927614\n",
      "creating raw data plot\n",
      "detecting peaks for  CC-147\n",
      "48  peaks\n",
      "1730  valleys\n",
      "eliminate multiple peaks for  CC-147\n",
      "setpoint 0.08640745998927614\n",
      "peaks to start 48\n",
      "peaks at end 32\n",
      "creating peak indexes for  CC-147\n",
      "time so far  3.298765000000003\n",
      "ShakeThresh =  1000, useTimeThresh =  0.16666666666666666, occasionTimeThresh =  1.0\n",
      "2393, 2422, 5793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booth.c.1\\OneDrive - Procter and Gamble\\Code\\SprayBit\\AE Dev v3\\AESprayBitUtil.py:292: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\booth.c.1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:299: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", 8157, 9416, 9444, 9482, 10854, 10893, 10921, 12176, 12266, 13494, 13652, 14869, 16145, 17422, 19819, 19856, 23153, 24467, 32038, 33456, 33558, 35370, 39951, 39996, 40026, 40055, 40085, 40114, 47585, data pts with neg data rate  0\n",
      "completed peak finding\n",
      "time for file so far  8.0790358\n",
      "defining spray direction for  CC-147\n",
      "setting day boundaries for  CC-147\n",
      "defining mass and angle for  CC-147\n",
      "creating excel for  CC-147\n",
      "Completed   CC-147\n",
      "\n",
      "time for this file  8.979960300000002\n",
      "\n",
      "generating dataframes for  CC-148\n",
      "Found  0  garbage lines\n",
      "calculating Data Rate for  CC-148\n",
      "start time was  2021-03-19 11:35:18.028000\n",
      "start time is now  2021-03-19 12:35:18.028000\n",
      "average data rate =  105.76888104492947\n",
      "Clean, filter and plot initial data  CC-148\n",
      "Cal value =  0.52059\n",
      "vhallMax =  0.5385742824497692\n",
      "setpoint =  0.1346435706124423\n",
      "creating raw data plot\n",
      "detecting peaks for  CC-148\n",
      "127  peaks\n",
      "2126  valleys\n",
      "eliminate multiple peaks for  CC-148\n",
      "setpoint 0.1346435706124423\n",
      "peaks to start 127\n",
      "peaks at end 27\n",
      "creating peak indexes for  CC-148\n",
      "time so far  2.591660900000008\n",
      "ShakeThresh =  1000, useTimeThresh =  0.16666666666666666, occasionTimeThresh =  1.0\n",
      "3874, 4436, 5628, 10273"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booth.c.1\\OneDrive - Procter and Gamble\\Code\\SprayBit\\AE Dev v3\\AESprayBitUtil.py:292: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\booth.c.1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:299: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", 10516, 10979, 11393, 12070, 12369, 12502, 12765, 19089, 22327, 22676, 24443, 24606, 25416, 25778, 26103, 32441, 38761, 39760, 40524, 43299, 50273, 56672, 60394, data pts with neg data rate  1\n",
      "error indexes  1\n",
      "completed peak finding\n",
      "time for file so far  8.52330830000001\n",
      "defining spray direction for  CC-148\n",
      "setting day boundaries for  CC-148\n",
      "defining mass and angle for  CC-148\n",
      "creating excel for  CC-148\n",
      "Completed   CC-148\n",
      "\n",
      "time for this file  9.425130800000005\n",
      "\n",
      "generating dataframes for  CC-149\n",
      "Found  0  garbage lines\n",
      "calculating Data Rate for  CC-149\n",
      "start time was  2021-03-20 12:25:37.028000\n",
      "start time is now  2021-03-20 13:25:37.028000\n",
      "average data rate =  104.24514213929497\n",
      "Clean, filter and plot initial data  CC-149\n",
      "Cal value =  0.51495\n",
      "vhallMax =  0.5277010074886908\n",
      "setpoint =  0.1319252518721727\n",
      "creating raw data plot\n",
      "detecting peaks for  CC-149\n",
      "478  peaks\n",
      "4433  valleys\n",
      "eliminate multiple peaks for  CC-149\n",
      "setpoint 0.1319252518721727\n",
      "peaks to start 478\n",
      "peaks at end 140\n",
      "creating peak indexes for  CC-149\n",
      "time so far  3.606901800000003\n",
      "ShakeThresh =  1000, useTimeThresh =  0.16666666666666666, occasionTimeThresh =  1.0\n",
      "3235, 3440, 9727, 15978"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booth.c.1\\OneDrive - Procter and Gamble\\Code\\SprayBit\\AE Dev v3\\AESprayBitUtil.py:292: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\booth.c.1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:299: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", 16474, 16809, 17178, 17311, 17738, 17818, 17965, 21231, 21878, 23184, 23442, 25621, 25803, 25909, 25988, 26086, 30399, 30509, 31380, 31581, 32706, 34186, 34669, 35431, 36925, 38313, 39545, 40045, 40292, 43525, 43587, 49840, 50352, 55375, 55542, 55743, 55845, 56027, 56310, 56760, 57125, 57996, 59840, 63903, 64482, 64652, 65207, 65521, 65767, 66254, 66469, 69584, 71777, 77174, 77275, 77513, 77992, 78428, 78939, 79045, 79369, 80180, 80821, 81084, 81136, 81241, 81338, 81379, 81644, 81922, 82425, 83617, 84217, 85942, 87943, 90580, 90800, 91637, 91834, 92126, 92446, 92655, 93351, 93599, 93850, 93989, 94200, 94387, 94428, 95452, 96600, 103056, 103505, 103609, 103782, 104057, 108467, 108500, 108968, 115290, 115714, 116253, 118560, 119427, 120057, 120205, 120740, 120945, 121120, 127411, 128698, 137055, 137258, 137682, 137711, 137735, 137788, 137812, 137932, 137968, 137996, 138026, 138077, 138104, 138149, 138208, 139130, 140471, 140606, 141493, 142266, 142554, 143227, 143445, 143615, 144673, data pts with neg data rate  1\n",
      "error indexes  1\n",
      "completed peak finding\n",
      "time for file so far  16.864586799999998\n",
      "defining spray direction for  CC-149\n",
      "setting day boundaries for  CC-149\n",
      "defining mass and angle for  CC-149\n",
      "creating excel for  CC-149\n",
      "Completed   CC-149\n",
      "\n",
      "time for this file  19.83925049999999\n",
      "\n",
      "generating dataframes for  CC-150\n",
      "Found  0  garbage lines\n",
      "calculating Data Rate for  CC-150\n",
      "start time was  2021-03-19 19:37:13.028000\n",
      "start time is now  2021-03-19 20:37:13.028000\n",
      "average data rate =  104.70133702953018\n",
      "Clean, filter and plot initial data  CC-150\n",
      "Cal value =  0.34088\n",
      "vhallMax =  0.26294542770258805\n",
      "setpoint =  0.06573635692564701\n",
      "creating raw data plot\n",
      "detecting peaks for  CC-150\n",
      "82  peaks\n",
      "1369  valleys\n",
      "eliminate multiple peaks for  CC-150\n",
      "setpoint 0.06573635692564701\n",
      "peaks to start 82\n",
      "peaks at end 15\n",
      "creating peak indexes for  CC-150\n",
      "time so far  2.67208269999999\n",
      "ShakeThresh =  1000, useTimeThresh =  0.16666666666666666, occasionTimeThresh =  1.0\n",
      "6240, 25112, 45540"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booth.c.1\\OneDrive - Procter and Gamble\\Code\\SprayBit\\AE Dev v3\\AESprayBitUtil.py:292: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\booth.c.1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:299: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", 45917, 47860, 48747, 63519, 67115, 69503, 70715, 71205, 71869, 73039, 73591, 74058, data pts with neg data rate  0\n",
      "completed peak finding\n",
      "time for file so far  6.657542100000001\n",
      "defining spray direction for  CC-150\n",
      "setting day boundaries for  CC-150\n",
      "defining mass and angle for  CC-150\n",
      "creating excel for  CC-150\n",
      "Completed   CC-150\n",
      "\n",
      "time for this file  7.542340199999998\n",
      "\n",
      "generating dataframes for  CC-151\n",
      "Found  0  garbage lines\n",
      "calculating Data Rate for  CC-151\n",
      "start time was  2021-03-19 17:24:34.018000\n",
      "start time is now  2021-03-19 18:24:34.018000\n",
      "average data rate =  106.76014328877088\n",
      "Clean, filter and plot initial data  CC-151\n",
      "Cal value =  0.45853\n",
      "vhallMax =  0.4744914877281622\n",
      "setpoint =  0.11862287193204055\n",
      "creating raw data plot\n",
      "detecting peaks for  CC-151\n",
      "284  peaks\n",
      "4591  valleys\n",
      "eliminate multiple peaks for  CC-151\n",
      "setpoint 0.11862287193204055\n",
      "peaks to start 284\n",
      "peaks at end 69\n",
      "creating peak indexes for  CC-151\n",
      "time so far  2.7096303999999947\n",
      "ShakeThresh =  1000, useTimeThresh =  0.16666666666666666, occasionTimeThresh =  1.0\n",
      "1231, 3440"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booth.c.1\\OneDrive - Procter and Gamble\\Code\\SprayBit\\AE Dev v3\\AESprayBitUtil.py:292: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\booth.c.1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:299: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", 4387, 4840, 8445, 8608, 8756, 8997, 10644, 11176, 11304, 11419, 12850, 13880, 14339, 14964, 15762, 16295, 18991, 21367, 22117, 23237, 27355, 31635, 32152, 32593, 33138, 34405, 34594, 34677, 36503, 37214, 37469, 43973, 46786, 49546, 49908, 50369, 51252, 55205, 55501, 55906, 55979, 56347, 57241, 57471, 58880, 59123, 59436, 59967, 60054, 60161, 61090, 61615, 62340, 63280, 64764, 64899, 65198, 65328, 69102, 69833, 70039, 70152, 70538, 71626, 72745, 73545, 76936, data pts with neg data rate  0\n",
      "completed peak finding\n",
      "time for file so far  11.628926500000006\n",
      "defining spray direction for  CC-151\n",
      "setting day boundaries for  CC-151\n",
      "defining mass and angle for  CC-151\n",
      "creating excel for  CC-151\n",
      "Completed   CC-151\n",
      "\n",
      "time for this file  13.0321498\n",
      "\n",
      "generating dataframes for  CC-152\n",
      "Found  0  garbage lines\n",
      "calculating Data Rate for  CC-152\n",
      "start time was  2021-03-20 09:38:41.028000\n",
      "start time is now  2021-03-20 10:38:41.028000\n",
      "average data rate =  104.6594520699298\n",
      "Clean, filter and plot initial data  CC-152\n",
      "Cal value =  0.31187\n",
      "vhallMax =  0.4301467072412606\n",
      "setpoint =  0.10753667681031515\n",
      "creating raw data plot\n",
      "detecting peaks for  CC-152\n",
      "106  peaks\n",
      "3037  valleys\n",
      "eliminate multiple peaks for  CC-152\n",
      "setpoint 0.10753667681031515\n",
      "peaks to start 106\n",
      "peaks at end 30\n",
      "creating peak indexes for  CC-152\n",
      "time so far  3.279913399999998\n",
      "ShakeThresh =  1000, useTimeThresh =  0.16666666666666666, occasionTimeThresh =  1.0\n",
      "3701, 6405, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booth.c.1\\OneDrive - Procter and Gamble\\Code\\SprayBit\\AE Dev v3\\AESprayBitUtil.py:292: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\booth.c.1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:299: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10685, 12277, 12410, 13706, 17176, 19349, 20440, 22559, 23746, 23791, 24837, 28172, 30235, 31486, 33929, 44024, 62942, 66291, 67507, 73938, 75186, 88911, 91222, 95485, 98607, 102962, 106311, 107803, data pts with neg data rate  0\n",
      "completed peak finding\n",
      "time for file so far  11.05438389999999\n",
      "defining spray direction for  CC-152\n",
      "setting day boundaries for  CC-152\n",
      "defining mass and angle for  CC-152\n",
      "creating excel for  CC-152\n",
      "Completed   CC-152\n",
      "\n",
      "time for this file  12.434145600000008\n",
      "\n",
      "generating dataframes for  CC-153\n",
      "Found  0  garbage lines\n",
      "calculating Data Rate for  CC-153\n",
      "start time was  2021-03-19 10:59:03.028000\n",
      "start time is now  2021-03-19 11:59:03.028000\n",
      "average data rate =  104.8758857849361\n",
      "Clean, filter and plot initial data  CC-153\n",
      "Cal value =  0.41018\n",
      "vhallMax =  0.48429948917895527\n",
      "setpoint =  0.12107487229473882\n",
      "creating raw data plot\n",
      "detecting peaks for  CC-153\n",
      "253  peaks\n",
      "6909  valleys\n",
      "eliminate multiple peaks for  CC-153\n",
      "setpoint 0.12107487229473882\n",
      "peaks to start 253\n",
      "peaks at end 102\n",
      "creating peak indexes for  CC-153\n",
      "time so far  5.906745000000001\n",
      "ShakeThresh =  1000, useTimeThresh =  0.16666666666666666, occasionTimeThresh =  1.0\n",
      "49882, 64839, 89240, 98909"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booth.c.1\\OneDrive - Procter and Gamble\\Code\\SprayBit\\AE Dev v3\\AESprayBitUtil.py:292: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\booth.c.1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:299: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", 99082, 110790, 111416, 113969, 114134, 122972, 128983, 135245, 135368, 135475, 135617, 141119, 141466, 147789, 148116, 148363, 148695, 149867, 150155, 161848, 162042, 164770, 164955, 165096, 167385, 167647, 167881, 168014, 168505, 168662, 169922, 170057, 172418, 172761, 181124, 189139, 190675, 196217, 200078, 206449, 207864, 214492, 214649, 214855, 215382, 215535, 216747, 216973, 217354, 217730, 218868, 219704, 219854, 220926, 221069, 229245, 236079, 236174, 236324, 236444, 236540, 236702, 236961, 237047, 237102, 239478, 240847, 242448, 242591, 243069, 245002, 245128, 245237, 246007, 252221, 252353, 253011, 255478, 255611, 256940, 257069, 263332, 271183, 271470, 272799, 272969, 273220, 275420, 276343, 276400, 278489, 279105, 279281, 279571, 279785, 283299, 283536, 283740, data pts with neg data rate  1\n",
      "error indexes  1\n",
      "completed peak finding\n",
      "time for file so far  18.677224799999976\n",
      "defining spray direction for  CC-153\n",
      "setting day boundaries for  CC-153\n",
      "defining mass and angle for  CC-153\n",
      "creating excel for  CC-153\n",
      "Completed   CC-153\n",
      "\n",
      "time for this file  21.883682899999997\n",
      "\n",
      "generating dataframes for  CC-154\n",
      "Found  0  garbage lines\n",
      "calculating Data Rate for  CC-154\n",
      "start time was  2021-03-20 07:57:10.028000\n",
      "start time is now  2021-03-20 08:57:10.028000\n",
      "average data rate =  104.34783816584475\n",
      "Clean, filter and plot initial data  CC-154\n",
      "Cal value =  0.46256\n",
      "vhallMax =  0.47183283720163727\n",
      "setpoint =  0.11795820930040932\n",
      "creating raw data plot\n",
      "detecting peaks for  CC-154\n",
      "455  peaks\n",
      "6869  valleys\n",
      "eliminate multiple peaks for  CC-154\n",
      "setpoint 0.11795820930040932\n",
      "peaks to start 455\n",
      "peaks at end 157\n",
      "creating peak indexes for  CC-154\n",
      "time so far  9.621855499999981\n",
      "ShakeThresh =  1000, useTimeThresh =  0.16666666666666666, occasionTimeThresh =  1.0\n",
      "6318, 8417, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booth.c.1\\OneDrive - Procter and Gamble\\Code\\SprayBit\\AE Dev v3\\AESprayBitUtil.py:292: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\booth.c.1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:299: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8702, 9120, 9543, 9639, 10009, 16293, 16601, 22577, 22601, 22733, 22867, 22892, 29604, 32169, 32525, 34572, 36926, 36992, 37093, 37142, 37367, 37594, 37938, 38162, 38270, 38526, 38730, 39086, 39182, 39945, 40404, 48214, 48421, 48522, 48906, 49006, 50098, 50465, 50606, 56870, 57560, 58942, 63318, 67598, 67713, 67905, 68099, 68381, 68850, 69214, 78972, 79227, 79373, 79552, 79786, 79958, 80236, 80765, 84292, 84657, 85043, 85741, 87182, 87346, 89609, 89805, 89901, 90098, 90280, 96322, 96688, 97019, 98216, 101670, 115400, 117506, 117646, 117809, 117972, 119592, 119964, 120250, 120950, 121114, 122317, 128921, 129415, 130465, 131728, 136164, 142528, 148896, 150350, 150838, 151385, 151714, 151956, 152184, 152262, 152417, 152580, 152951, 153139, 153795, 184112, 184483, 184726, 184988, 185142, 186341, 186520, 186740, 186841, 187081, 187181, 187524, 188081, 189909, 196092, 196220, 196552, 196827, 197746, 198041, 201275, 267007, 268305, 271213, 271416, 272510, 356903, 357074, 357754, 358021, 358128, 358332, 358496, 359153, 359551, 359855, 360059, 360480, 360920, 362001, 362116, 362424, 362970, 363822, 366601, 366854, 366999, 367559, 373295, 375057, 387694, data pts with neg data rate  1\n",
      "error indexes  1\n",
      "completed peak finding\n",
      "time for file so far  29.7183268\n",
      "defining spray direction for  CC-154\n",
      "setting day boundaries for  CC-154\n",
      "defining mass and angle for  CC-154\n",
      "creating excel for  CC-154\n",
      "Completed   CC-154\n",
      "\n",
      "time for this file  34.7258176\n",
      "\n",
      "generating dataframes for  CC-155\n",
      "Found  0  garbage lines\n",
      "calculating Data Rate for  CC-155\n",
      "start time was  2021-03-20 09:27:48.028000\n",
      "start time is now  2021-03-20 10:27:48.028000\n",
      "average data rate =  104.53491557385861\n",
      "Clean, filter and plot initial data  CC-155\n",
      "Cal value =  0.43839\n",
      "vhallMax =  0.4746295653839832\n",
      "setpoint =  0.1186573913459958\n",
      "creating raw data plot\n",
      "detecting peaks for  CC-155\n",
      "30  peaks\n",
      "2999  valleys\n",
      "eliminate multiple peaks for  CC-155\n",
      "setpoint 0.1186573913459958\n",
      "peaks to start 30\n",
      "peaks at end 16\n",
      "creating peak indexes for  CC-155\n",
      "time so far  4.529390199999995\n",
      "ShakeThresh =  1000, useTimeThresh =  0.16666666666666666, occasionTimeThresh =  1.0\n",
      "9973, 12547, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booth.c.1\\OneDrive - Procter and Gamble\\Code\\SprayBit\\AE Dev v3\\AESprayBitUtil.py:292: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\booth.c.1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:299: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16257, 21083, 27323, 36835, 40515, 46377, 52220, 58047, 63704, 68695, 75006, 77394, 83654, 94785, data pts with neg data rate  0\n",
      "completed peak finding\n",
      "time for file so far  8.930260099999998\n",
      "defining spray direction for  CC-155\n",
      "setting day boundaries for  CC-155\n",
      "defining mass and angle for  CC-155\n",
      "creating excel for  CC-155\n",
      "Completed   CC-155\n",
      "\n",
      "time for this file  9.939909099999994\n",
      "\n",
      "generating dataframes for  CC-156\n",
      "Found  0  garbage lines\n",
      "calculating Data Rate for  CC-156\n",
      "start time was  2021-03-20 08:30:10.028000\n",
      "start time is now  2021-03-20 09:30:10.028000\n",
      "average data rate =  105.18248474565627\n",
      "Clean, filter and plot initial data  CC-156\n",
      "Cal value =  0.24418\n",
      "vhallMax =  0.3354064034668644\n",
      "setpoint =  0.0838516008667161\n",
      "creating raw data plot\n",
      "detecting peaks for  CC-156\n",
      "118  peaks\n",
      "2313  valleys\n",
      "eliminate multiple peaks for  CC-156\n",
      "setpoint 0.0838516008667161\n",
      "peaks to start 118\n",
      "peaks at end 25\n",
      "creating peak indexes for  CC-156\n",
      "time so far  2.6409834000000103\n",
      "ShakeThresh =  1000, useTimeThresh =  0.16666666666666666, occasionTimeThresh =  1.0\n",
      "2623, 2993, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booth.c.1\\OneDrive - Procter and Gamble\\Code\\SprayBit\\AE Dev v3\\AESprayBitUtil.py:292: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\booth.c.1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:299: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3036, 3430, 18178, 18339, 19966, 30871, 32202, 32321, 32478, 38833, 38931, 39665, 39795, 44532, 45066, 47338, 50200, 55130, 61722, 66431, 72822, 73128, 76499, data pts with neg data rate  2\n",
      "error indexes  2\n",
      "completed peak finding\n",
      "time for file so far  7.3419782\n",
      "defining spray direction for  CC-156\n",
      "setting day boundaries for  CC-156\n",
      "defining mass and angle for  CC-156\n",
      "creating excel for  CC-156\n",
      "Completed   CC-156\n",
      "\n",
      "time for this file  8.364400100000012\n",
      "\n",
      "generating dataframes for  CC-157\n",
      "Found  0  garbage lines\n",
      "calculating Data Rate for  CC-157\n",
      "start time was  2021-03-20 08:44:53.028000\n",
      "start time is now  2021-03-20 09:44:53.028000\n",
      "average data rate =  106.12232181997183\n",
      "Clean, filter and plot initial data  CC-157\n",
      "Cal value =  0.303\n",
      "vhallMax =  0.48319947731700424\n",
      "setpoint =  0.12079986932925106\n",
      "creating raw data plot\n",
      "detecting peaks for  CC-157\n",
      "462  peaks\n",
      "8589  valleys\n",
      "eliminate multiple peaks for  CC-157\n",
      "setpoint 0.12079986932925106\n",
      "peaks to start 462\n",
      "peaks at end 222\n",
      "creating peak indexes for  CC-157\n",
      "time so far  4.992562200000009\n",
      "ShakeThresh =  1000, useTimeThresh =  0.16666666666666666, occasionTimeThresh =  1.0\n",
      "1042, 1714, 4207, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booth.c.1\\OneDrive - Procter and Gamble\\Code\\SprayBit\\AE Dev v3\\AESprayBitUtil.py:292: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\booth.c.1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:299: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4974, 5095, 5587, 9797, 9979, 10408, 10608, 10733, 12099, 12248, 12628, 20072, 20120, 21386, 22666, 22722, 23955, 25134, 25559, 26501, 26713, 28936, 36503, 36987, 41370, 42588, 42751, 44123, 44255, 44587, 45095, 45211, 45690, 49079, 49195, 49320, 49707, 49855, 50538, 50652, 51008, 53232, 53314, 53415, 53637, 53804, 53830, 53971, 54000, 55158, 55270, 56539, 57698, 58870, 62125, 62273, 62590, 63196, 63424, 63503, 64174, 64629, 65734, 65894, 67201, 68356, 69681, 72009, 72121, 73583, 74756, 75883, 77044, 78204, 80449, 81672, 84154, 84587, 87143, 87279, 87407, 89817, 90035, 90094, 90568, 91885, 92177, 92583, 93723, 96008, 97282, 97454, 97547, 97654, 97836, 99994, 100080, 100170, 101796, 102524, 102662, 102884, 103018, 103161, 103331, 105510, 106013, 106235, 106537, 106658, 106794, 108085, 108436, 108615, 113198, 113339, 113597, 113950, 114073, 114441, 114469, 115828, 115945, 116381, 117674, 118103, 119385, 125716, 127707, 136560, 136784, 136884, 137029, 137113, 137151, 137245, 139443, 140959, 141071, 142252, 142348, 145669, 145884, 146020, 146212, 146413, 146538, 146620, 147938, 148053, 148191, 148405, 148585, 148633, 153919, 154123, 155726, 155861, 155962, 156032, 156208, 156322, 156754, 164270, 165663, 165987, 166142, 166258, 166500, 166981, 167207, 168232, 168328, 168540, 168641, 168745, 175050, 175317, 175416, 175505, 175620, 175769, 175892, 176219, 176851, 177060, 177144, 183600, 183850, 184025, 184273, 184389, 184755, 184912, 185585, 185877, 187239, 187412, 187570, 187613, 187965, 188121, 188228, 188421, 188839, 188982, 189092, 189201, 189753, 189945, 190502, 191393, 191692, 191835, 196685, 209324, 209475, 209769, 209887, data pts with neg data rate  1\n",
      "error indexes  1\n",
      "completed peak finding\n",
      "time for file so far  25.93119039999999\n",
      "defining spray direction for  CC-157\n",
      "setting day boundaries for  CC-157\n",
      "defining mass and angle for  CC-157\n",
      "creating excel for  CC-157\n",
      "Completed   CC-157\n",
      "\n",
      "time for this file  30.760195100000004\n",
      "\n",
      "generating dataframes for  CC-158\n",
      "Found  0  garbage lines\n",
      "calculating Data Rate for  CC-158\n",
      "start time was  2021-03-20 01:29:54.028000\n",
      "start time is now  2021-03-20 02:29:54.028000\n",
      "average data rate =  105.8807764632667\n",
      "Clean, filter and plot initial data  CC-158\n",
      "Cal value =  0.44725\n",
      "vhallMax =  0.44322293563219883\n",
      "setpoint =  0.11080573390804971\n",
      "creating raw data plot\n",
      "detecting peaks for  CC-158\n",
      "289  peaks\n",
      "6038  valleys\n",
      "eliminate multiple peaks for  CC-158\n",
      "setpoint 0.11080573390804971\n",
      "peaks to start 289\n",
      "peaks at end 121\n",
      "creating peak indexes for  CC-158\n",
      "time so far  3.6653061000000093\n",
      "ShakeThresh =  1000, useTimeThresh =  0.16666666666666666, occasionTimeThresh =  1.0\n",
      "189, 6701, 13964, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booth.c.1\\OneDrive - Procter and Gamble\\Code\\SprayBit\\AE Dev v3\\AESprayBitUtil.py:292: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\booth.c.1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:299: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14867, 15134, 15477, 27258, 27808, 31413, 31600, 31693, 31812, 31946, 32001, 32214, 32324, 32427, 33034, 33236, 33353, 33481, 33528, 33574, 33644, 33764, 33802, 33960, 36040, 36342, 36881, 37591, 38989, 39104, 40112, 40160, 40817, 41778, 41863, 41936, 42293, 42586, 42764, 42944, 43011, 43034, 43145, 43310, 43424, 43561, 43746, 43891, 44011, 44118, 44210, 44272, 44614, 44766, 44851, 49354, 53278, 55327, 55557, 55776, 55954, 56080, 56547, 81995, 83664, 86152, 88778, 88879, 90222, 90396, 90612, 101744, 108266, 109890, 114164, 120636, 127144, 133658, 140044, 140116, 140222, 140320, 140572, 140664, 140751, 140827, 140877, 140952, 141004, 141047, 141107, 141142, 141173, 141201, 144389, 144447, 144506, 144547, 144580, 144610, 144642, 144672, 144701, 144729, 144756, 144783, 144808, 144833, 144859, 144883, 144907, 144932, 144958, 144984, 145011, 145039, 145067, 145093, data pts with neg data rate  2\n",
      "error indexes  2\n",
      "completed peak finding\n",
      "time for file so far  14.804047699999984\n",
      "defining spray direction for  CC-158\n",
      "setting day boundaries for  CC-158\n",
      "defining mass and angle for  CC-158\n",
      "creating excel for  CC-158\n",
      "Completed   CC-158\n",
      "\n",
      "time for this file  17.105615800000038\n",
      "\n",
      "generating dataframes for  CC-159\n",
      "Found  0  garbage lines\n",
      "calculating Data Rate for  CC-159\n",
      "start time was  2021-03-20 08:49:44.028000\n",
      "start time is now  2021-03-20 09:49:44.028000\n",
      "average data rate =  104.47873195887404\n",
      "Clean, filter and plot initial data  CC-159\n",
      "Cal value =  0.23451\n",
      "vhallMax =  0.44680060357213663\n",
      "setpoint =  0.11170015089303416\n",
      "creating raw data plot\n",
      "detecting peaks for  CC-159\n",
      "71  peaks\n",
      "758  valleys\n",
      "eliminate multiple peaks for  CC-159\n",
      "setpoint 0.11170015089303416\n",
      "peaks to start 71\n",
      "peaks at end 26\n",
      "creating peak indexes for  CC-159\n",
      "time so far  3.750918899999988\n",
      "ShakeThresh =  1000, useTimeThresh =  0.16666666666666666, occasionTimeThresh =  1.0\n",
      "24893, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booth.c.1\\OneDrive - Procter and Gamble\\Code\\SprayBit\\AE Dev v3\\AESprayBitUtil.py:292: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\booth.c.1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:299: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25014, 25131, 25348, 25670, 25930, 28263, 30623, 30680, 30763, 31168, 31488, 31940, 32226, 32425, 32614, 32937, 34099, 34487, 34769, 35301, 35710, 35817, 35995, 36096, 67265, data pts with neg data rate  0\n",
      "completed peak finding\n",
      "time for file so far  10.313000899999963\n",
      "defining spray direction for  CC-159\n",
      "setting day boundaries for  CC-159\n",
      "defining mass and angle for  CC-159\n",
      "creating excel for  CC-159\n",
      "Completed   CC-159\n",
      "\n",
      "time for this file  11.105832799999973\n",
      "\n",
      "generating dataframes for  CC-160\n",
      "Found  0  garbage lines\n",
      "calculating Data Rate for  CC-160\n",
      "start time was  2021-03-19 12:33:47.028000\n",
      "start time is now  2021-03-19 13:33:47.028000\n",
      "average data rate =  105.80460210346187\n",
      "Clean, filter and plot initial data  CC-160\n",
      "Cal value =  0.60923\n",
      "vhallMax =  0.6415576093334217\n",
      "setpoint =  0.1603894023333554\n",
      "creating raw data plot\n",
      "detecting peaks for  CC-160\n",
      "129  peaks\n",
      "2264  valleys\n",
      "eliminate multiple peaks for  CC-160\n",
      "setpoint 0.1603894023333554\n",
      "peaks to start 129\n",
      "peaks at end 62\n",
      "creating peak indexes for  CC-160\n",
      "time so far  3.4310049999999706\n",
      "ShakeThresh =  1000, useTimeThresh =  0.16666666666666666, occasionTimeThresh =  1.0\n",
      "25583, 25628, 25802, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booth.c.1\\OneDrive - Procter and Gamble\\Code\\SprayBit\\AE Dev v3\\AESprayBitUtil.py:292: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\booth.c.1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:299: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25848, 25885, 25920, 26688, 26762, 27191, 27612, 43642, 44940, 45009, 45050, 45090, 68399, 68440, 68575, 69112, 69148, 69240, 69283, 69330, 69621, 69657, 69755, 78220, 78680, 80313, 86761, 86799, 86833, 86863, 86894, 86924, 86955, 87014, 88238, 88511, 88842, 89758, 89859, 90454, 90669, 91057, 91280, 91462, 91873, 92392, 92689, 94995, 95235, 99603, 99643, 99739, 99784, 99819, 99851, 99883, 99932, 142217, 142360, data pts with neg data rate  0\n",
      "completed peak finding\n",
      "time for file so far  10.291442700000005\n",
      "defining spray direction for  CC-160\n",
      "setting day boundaries for  CC-160\n",
      "defining mass and angle for  CC-160\n",
      "creating excel for  CC-160\n",
      "Completed   CC-160\n",
      "\n",
      "time for this file  12.267549499999973\n",
      "\n",
      "All Files complete\n",
      "time for all files 230.8465528\n"
     ]
    }
   ],
   "source": [
    "#Import Data (Raw Data)\n",
    "totalStartTime=timeit.default_timer()\n",
    "df=pd.DataFrame()\n",
    "df2=pd.DataFrame()\n",
    "df2a=pd.DataFrame()\n",
    "resultTotal=pd.DataFrame()\n",
    "\n",
    "#factor by which to multiply max vhall to set min peak height for detection\n",
    "setpointFactor=0.25\n",
    "\n",
    "# Create summary table of key data attributes for each user\n",
    "dfSummary=pd.DataFrame(columns = ['User', 'Start_date', 'End_Date', 'Total_Data_Points','Strokes_Count',\n",
    "                                  'data_errors','Wake_Strokes'])\n",
    "# dfSum=pd.DataFrame(columns = ['User', 'setpoint', 'Start_date', 'End_Date', 'Data_Points', 'Strokes_Count'])\n",
    "\n",
    "# print(legFolders)\n",
    "# print(folderID)\n",
    "# folderID=''\n",
    "# for folderId2 in legFolders:\n",
    "# print(folderId2)\n",
    "dataLocation = dataDir + \"/\"   \n",
    "resultDirChart = dataLocation +'ResultCharts/'    #set where to place charts\n",
    "resultDirXL = dataLocation +'Result_xl/'    #set where to place preprocessed results \n",
    "\n",
    "if csvFormat:\n",
    "    filesA = [f for f in os.listdir(dataLocation) if f.endswith('.' + 'csv')]\n",
    "else:\n",
    "    filesA = [f for f in os.listdir(dataLocation)]  #****  if files are not in .csv then \n",
    "                                                    #no other files can be in directory\n",
    "\n",
    "# remove folders from file list if not in csv format \n",
    "if not csvFormat:\n",
    "    for x in removeFolders:        \n",
    "        filesA.remove(x)\n",
    "#         filesA.remove('Resultb')\n",
    "#         filesA.remove('Error')\n",
    "\n",
    "if csvFormat:\n",
    "    filesB = [x[:-4] for x in filesA]   #remove extension so result files are named cleanly\n",
    "else:\n",
    "    filesB = filesA   # no need to modify if not saved as csv\n",
    "files=filesB\n",
    "print(files)    \n",
    "\n",
    "for i in files:\n",
    "    skip = False  #skip data save on break from loop due to error\n",
    "    fileStartTime=timeit.default_timer()\n",
    "    try:         \n",
    "        filename = i\n",
    "#         print(i)\n",
    "        User=filename\n",
    "        print('generating dataframes for ', filename )\n",
    "        text_row=False     #to screen out text at top of some files\n",
    "        if csvFormat:\n",
    "            joinedfilename = dataLocation + filename + extension\n",
    "        else:\n",
    "            print('need to add for non csv format')\n",
    "#         csvTest='x'\n",
    "        garbageLines=0            \n",
    "\n",
    "        #util to read in header info with calval and df with data\n",
    "        calval,df,calval_index,value = readCalVal(joinedfilename,garbageLines,old_board) \n",
    "\n",
    "    except Exception as e:\n",
    "        print('error generating dataframes for ', filename,e )\n",
    "        print('')\n",
    "        dfSummary = dfSummary.append({'User': User,'File Error':e}, ignore_index=True)\n",
    "        continue  #goto next file\n",
    "\n",
    "    try:\n",
    "        if debug:\n",
    "            print('calculating Data Rate for ', filename)\n",
    "\n",
    "        #Check for blank cells\n",
    "        df.isnull().values.any()\n",
    "#         print(df)\n",
    "\n",
    "        #util for finding data rate\n",
    "        dft,Start_date,End_Date,Data_Points,datarate = readDataRate(df)\n",
    "        \n",
    "        #shift the timestamp if needed(for daylight savings?)\n",
    "        if(requiresTimeShift == True):\n",
    "            originalStartDateTime=df['datetime'].iloc[0]\n",
    "            df['datetime']=df['datetime'] + datetime.timedelta(minutes=timeShiftMins)\n",
    "            fixedStartDateTime=df['datetime'].iloc[0]\n",
    "            print('start time was ', originalStartDateTime)\n",
    "            print('start time is now ', fixedStartDateTime)\n",
    "            \n",
    "\n",
    "        print('average data rate = ',datarate)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('***Error calculating Data Rate for ', filename,e )\n",
    "        print('')\n",
    "        dfSummary = dfSummary.append({'User': User,'File Error':e}, ignore_index=True)\n",
    "        continue  #goto next file\n",
    "\n",
    "    try:\n",
    "        if debug:\n",
    "            print('Clean, filter and plot initial data ', filename )\n",
    "\n",
    "#         print ('Cal value = ', value)\n",
    "#         df2,setpoint,vhallMax=dataCleanUp(dft,setpointFactor)\n",
    "\n",
    "        #smooth vhall signal\n",
    "        df2=LowPassFilt(dft,'vhall3')\n",
    "        \n",
    "        \n",
    "        print ('Cal value = ', value)\n",
    "        df2,setpoint,vhallMax=dataCleanUp(df2,setpointFactor)\n",
    "\n",
    "\n",
    "#         #plotly of filtered data\n",
    "#         fig = px.line(x=df2.index, y=df2.vhall3)\n",
    "#         fig.write_html(resultDirChart + 'Raw_'+filename+'.html')\n",
    "\n",
    "        #plotly of date/vhall data\n",
    "#         fig = px.line(x=df2.datetime, y=df2.vhall3)\n",
    "#         fig.write_html(resultDirChart + 'DatePlot_'+filename+'.html')\n",
    "        \n",
    "        \n",
    "        x_name='datetime'\n",
    "        y_name='vhall3'\n",
    "\n",
    "        x_scat = df[x_name]\n",
    "        y_scat = df[y_name]\n",
    "\n",
    "        fig, ax = plt.subplots(1,1) #Add subplot to figure\n",
    "        plt.plot(x_scat,y_scat)\n",
    "        fig.set_size_inches(16,9)\n",
    "        ax.set_xlabel(x_name)\n",
    "        ax.set_ylabel(y_name)\n",
    "    #     plt.show()\n",
    "        picname = resultDirChart + 'DatePlot_' + filename  + '.png'\n",
    "        fig.savefig(picname, transparent=False)\n",
    "        plt.close(fig)\n",
    "\n",
    "        #Creating vector sum of 3axis gyro data and smooth with bandpass filter\n",
    "        df2=createVectorSumMotion(df2)\n",
    "        df2a=LowPassFilt(df2,'MotionVector')\n",
    "\n",
    "\n",
    "        if debug:\n",
    "            print('creating raw data plot')\n",
    "\n",
    "    #----------------------------------------\n",
    "        #screen for only active study date data\n",
    "#         mask = (df2a['datetime'] > first_time) & (df2a['datetime'] <= second_time)\n",
    "#         df2a = df2a.loc[mask].copy()  \n",
    "\n",
    "#             Study_Start_Date= df2a['datetime'].iloc[0]\n",
    "#             Study_End_Date= df2a['datetime'].iloc[len(df2a)-1]\n",
    "#             Study_Data_Points= len(df2a)\n",
    "    #---------------------------------\n",
    "\n",
    "    except Exception as e:\n",
    "        print('***error filter and plotting inital data ', filename,e )\n",
    "        print('')\n",
    "        dfSummary = dfSummary.append({'User': User,'File Error':e}, ignore_index=True)\n",
    "        continue  #goto next file\n",
    "\n",
    "    #----------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    #----------------------------------------\n",
    "        #In this step i'm using a peak finder analysis (detect_peaks.py) to evaluate trigger sprayer features.  \n",
    "        # I've left minimum peak distance \"mpd\" at a minimal seperation of 20 frames. \n",
    "        #   setpoint defined above as ratio of max signal        \n",
    "\n",
    "\n",
    "    try:\n",
    "        if debug:\n",
    "            print('detecting peaks for ', filename )\n",
    "        # detect  peaks \n",
    "        ind = detect_peaks(df2a.vhall3, mph=setpoint, mpd=20, show=False, edge='rising')\n",
    "        Strokes_Count= len(ind)\n",
    "        print(Strokes_Count,' peaks') #Show me how many peaks found\n",
    "#         if Strokes_Count > strokeLimit:\n",
    "#             print('Too many peaks, stopping after detect_peak on: ', filename)\n",
    "#             print('')\n",
    "#             e=Strokes_Count, ' peaks'\n",
    "#             dfSummary = dfSummary.append({'User': User,'File Error':e}, ignore_index=True)\n",
    "#             continue\n",
    "\n",
    "        #invert the vhall data and rerun peak finder to identify the base of peaks\n",
    "\n",
    "        # indValley = detect_peaks(-df2a.vhall3, mph=setpoint, mpd=25, show=False, edge='rising')\n",
    "        indValley, _ = scipy.signal.find_peaks(-df2a.vhall3, height = -setpoint, threshold = None, distance=20)\n",
    "        print(len(indValley),' valleys') #Show me how many peaks found\n",
    "\n",
    "    except Exception as e:\n",
    "        print('***error detecting peaks for ', filename,e )\n",
    "        print('')\n",
    "        dfSummary = dfSummary.append({'User': User,'File Error':e}, ignore_index=True)\n",
    "        continue  #goto next file\n",
    "\n",
    "    #----------------------------------------\n",
    "\n",
    "    try:\n",
    "        if debug:\n",
    "            print('eliminate multiple peaks for ', filename )\n",
    "\n",
    "        #for each peak, verify the signal returns below setpoint before the next peak\n",
    "        #  to eliminate multiple peaks identified on noisy signal while trigger is held down\n",
    "\n",
    "        #util for eliminate peaks\n",
    "        ind = eliminateMultiplePeaks(df2a,ind,setpoint)\n",
    "        if len(ind) > strokeLimit:\n",
    "            print('Too many peaks, stopping after detect_peak on: ', filename)\n",
    "            print('')\n",
    "            e=Strokes_Count, ' peaks'\n",
    "            dfSummary = dfSummary.append({'User': User,'File Error':e}, ignore_index=True)\n",
    "            continue\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print('***error eliminating multiple peaks for  ', filename,e )\n",
    "        print('')\n",
    "        dfSummary = dfSummary.append({'User': User,'File Error':e}, ignore_index=True)\n",
    "        continue  #goto next file\n",
    "\n",
    "\n",
    "#----------------------------------------    \n",
    "    try:\n",
    "        if debug:\n",
    "            print('creating peak indexes for ', filename )\n",
    "            print('time so far ',timeit.default_timer()-fileStartTime)\n",
    "\n",
    "#----------------------------------------\n",
    "        # In this step, I will locate the roots of every found peak, and calculate duration of stroke.\n",
    "        # I locate roots by searching the list of valleys for the first ind before and after each peak\n",
    "\n",
    "\n",
    "#         df2c=df2a.copy()\n",
    "        amount= setpoint\n",
    "        width=[]\n",
    "        width2=[]\n",
    "        inddex=[]\n",
    "        inddex2=[]\n",
    "        peakindex=[]\n",
    "        dataRateErrors=0\n",
    "        dferror = pd.DataFrame()\n",
    "        df2d = pd.DataFrame()        \n",
    "#         df2d = dft.reset_index()  #create new df with index ids as column from unfiltered data\n",
    "        df2d = df2a.reset_index()  #Change to filtered data\n",
    "\n",
    "        shakeList=[]\n",
    "        shakeMax=[]\n",
    "        sweep=[]\n",
    "        degPerSec=[]\n",
    "        sprayDirectionMin=[]\n",
    "        sprayDirectionMax=[]\n",
    "        sprayDirectionMode=[]\n",
    "        UseMovementSec=[]\n",
    "        OccMovementSec=[]\n",
    "        pctFullStroke=[]\n",
    "        print('ShakeThresh = ',accelThresh, end=', ')\n",
    "        print('useTimeThresh = ',useTimeMin, end=', ')\n",
    "        print('occasionTimeThresh = ',occasionTimeMin)\n",
    "        \n",
    "#         def defineMovementTime(dfMove,i,useTimeMin,datarate):\n",
    "            \n",
    "#             peakTime = pd.to_datetime(dfMove['datetime'].iloc[i])\n",
    "#             dataStartUse=peakTime - datetime.timedelta(minutes=useTimeMin)\n",
    "#             # filter by time prior to peak:\n",
    "#             mask = (dfMove['datetime'] > dataStartUse) & (dfMove['datetime'] <= peakTime)\n",
    "#             dfMove2 = dfMove.loc[mask].copy()\n",
    "#             movementDurationSecs = len(dfMove2)/datarate\n",
    "            \n",
    "#             return movementDurationSecs\n",
    "            \n",
    "\n",
    "\n",
    "        #iterate through each peak index identified\n",
    "        for i in ind:\n",
    "            peaklocation = i\n",
    "            peakindex.append(peaklocation)\n",
    "\n",
    "            #util\n",
    "            tempindex,tempindex2,inddex,inddex2,width,width2,totalDur,vhallPeak = findStrokeStartEnd(df2d,i,ind,indValley,datarate,\n",
    "                                                                                  inddex,inddex2,width,width2)\n",
    "            \n",
    "            #report percent of max vhall for this stroke\n",
    "            pctFullStroke.append(vhallPeak/vhallMax*100)\n",
    "\n",
    "            #util  create df to contain all data points within peaks found for further study\n",
    "            dferror,dfFullStroke = dfOfEachStroke(df2d,tempindex,tempindex2,dferror)\n",
    "\n",
    "            # Util describe sweeping motion in degrees of movement and deg/sec\n",
    "            sweep, degPerSec = defineSweepBehavior(dfFullStroke,sweep,degPerSec,totalDur)\n",
    "\n",
    "            # Util  describe shake behavior\n",
    "#             shakeList,shakeMax = defineShakeBehavior(df2c,i,dataStartMin,shakeList,shakeMax,accelThresh,datarate)\n",
    "            shakeList,shakeMax = defineShakeBehavior(df2d,i,dataStartMin,shakeList,shakeMax,accelThresh,datarate)\n",
    "            \n",
    "            # Util  get spray direction for every data point in the spray\n",
    "            dfFullStroke['sprayDirection']=[FR_DefineSprayDirectionV2(x,y) for x,y in zip(dfFullStroke['pitch'],\n",
    "                                                                                          dfFullStroke['roll'])]\n",
    "            #get min and max angles of spray\n",
    "            sprayDirectionMin.append(dfFullStroke['sprayDirection'].min())\n",
    "            sprayDirectionMax.append(dfFullStroke['sprayDirection'].max())\n",
    "            #get the most common direction for the full spray\n",
    "            #series.mode()returns a list to allow for cases where there are ties in the count of values\n",
    "            #we will use the value with highest magnitude (absolute value) aka worst case\n",
    "            sprayDirectionMode.append(max(dfFullStroke['sprayDirection'].mode(),key=abs))\n",
    "            \n",
    "            #Get Duration of motion prior to spray for insight into if bottle was moved prior to spray\n",
    "            #  we will look at the prior 10 sec and 60 sec to each spray\n",
    "            #  --this should coorelate to 'uses' and 'occasions' in post processing\n",
    "            #  in that pre-spray time we count the number of data points to get the time\n",
    "            #  the unit was awake and recording prior to the spray\n",
    "            #  this will also catch events where unit was in protected mode and \n",
    "            #  only woke on the trigger movement\n",
    "            UseMovementSec=defineMovementTime(df2d,i,useTimeMin,datarate,UseMovementSec)\n",
    "            OccMovementSec=defineMovementTime(df2d,i,occasionTimeMin,datarate,OccMovementSec)\n",
    "            \n",
    "            #report percent of max vhall for this stroke\n",
    "            \n",
    "    \n",
    "    \n",
    "            # end of individual stoke attribute definition\n",
    "\n",
    "#       report data points within a stroke with negative data rate --ie saved out of order\n",
    "        dferror=dferror[dferror['localdatarate']<0]\n",
    "        dataErrorsCnt = len(dferror)\n",
    "        if debug: print('data pts with neg data rate ',dataErrorsCnt)\n",
    "        if dataErrorsCnt >0:\n",
    "#             dataRateErrors = dferror['index']\n",
    "            dataRateErrors = dataErrorsCnt\n",
    "            print('error indexes ', dataRateErrors)\n",
    "\n",
    "#       report mean value of data points not part of a stroke for baseline\n",
    "        dfBaseline=df2a.loc[~df2a.index.isin(dferror['index'])]\n",
    "        avgBaseline=round(dfBaseline.vhall3.mean(),5)\n",
    "\n",
    "\n",
    "        #add extracted features of each spray to table\n",
    "#         indexlist = pd.DataFrame({'inddex':inddex,'inddex2':inddex2, 'duration':width, 'fduration':width2,\n",
    "#                                   'peakindex':peakindex})\n",
    "        indexlist = pd.DataFrame({'inddex':inddex,'inddex2':inddex2, 'duration':width, 'fduration':width2,\n",
    "                          'peakindex':peakindex, 'ShakeTime':shakeList, 'ShakeMax':shakeMax,\n",
    "                                'Sweep':sweep, 'SweepRate':degPerSec, 'DirectionMin':sprayDirectionMin,\n",
    "                                'DirectionMax':sprayDirectionMax,'DirectionMode':sprayDirectionMode,\n",
    "                                 'UseMovementSec':UseMovementSec , 'OccMovementSec':OccMovementSec,\n",
    "                                 'PrctFullStroke':pctFullStroke})\n",
    "#         print('complete sweep4')\n",
    "\n",
    "\n",
    "#----------------------------------------\n",
    "        # In this step I find multiple peaks with index between each left/right root.  The logic at play...\n",
    "        #    is that if more than one peak is found between a root pair location, it must either be invalid, or indication...\n",
    "        #       of a partial stroke behavior.\n",
    "        indexlist.drop_duplicates(subset=['inddex', 'inddex2'], keep='first', inplace =True)\n",
    "        indexlist = indexlist.reset_index(drop=True)\n",
    "\n",
    "        # In this step I'm removing the invalid indexes & partial stroke indexes..\n",
    "        #    from our original ind list that was generated by the peakfinder routine\n",
    "        newind=indexlist['peakindex'].tolist()\n",
    "        Strokes_Count= len(newind)\n",
    "\n",
    "        #plotly of all data with start and end of peaks indentified\n",
    "        fig=px.line(df2a, y='vhall3')\n",
    "        fig.add_scatter(x=indexlist.inddex2, y=df2a['vhall3'][indexlist.inddex2],mode='markers', name='Start')\n",
    "        fig.add_scatter(x=newind, y=df2a['vhall3'][newind],mode='markers', name='Peak')\n",
    "        fig.add_scatter(x=indexlist.inddex, y=df2a['vhall3'][indexlist.inddex],mode='markers', name='End')\n",
    "#         fig.add_scatter(x=indexlist.inddex2, y=df2a['vhall3'][indexlist.inddex2]-setpoint/10,mode='markers', name='Start')\n",
    "#         fig.add_scatter(x=indexlist.inddex2, y=df2a['vhall3'][indexlist.inddex2],mode='markers', name='Start')\n",
    "        fig.write_html(resultDirChart + 'peaks_'+filename+'.html')\n",
    "#         fig.show()\n",
    "\n",
    "        print('completed peak finding')\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print('***error creating peak indexes for ', filename,e )\n",
    "        print('')\n",
    "        dfSummary = dfSummary.append({'User': User,'File Error':e}, ignore_index=True)\n",
    "        continue  #goto next file\n",
    "\n",
    "    \n",
    "    \n",
    "    print('time for file so far ',timeit.default_timer()-fileStartTime)\n",
    "    try:\n",
    "        if debug:\n",
    "            print('defining spray direction for ', filename ) \n",
    "#----------------------------------------\n",
    "        #Evaluate angle of spray for each stroke in total file\n",
    "#         print ('spray angle')\n",
    "\n",
    "        df2a = FR_DefineSprayDirection(df2a)\n",
    "#         df2a['SprayDirection']= [FR_DefineSprayDirectionV2(x,y) for x,y in zip(df2a['pitch'],df2a['roll'])]\n",
    "            \n",
    "            \n",
    "    except Exception as e:\n",
    "        print('***error defining spray direction for ', filename,e )\n",
    "        print('')\n",
    "        dfSummary = dfSummary.append({'User': User,'File Error':e}, ignore_index=True)\n",
    "        continue  #goto next file\n",
    "\n",
    "    try:\n",
    "        if debug:\n",
    "            print('setting day boundaries for ', filename )       \n",
    "#----------------------------------------\n",
    "        #Draw lines at each wakeup/sleep boundary---changing all df2 to df2a\n",
    "#         print('wake boundary')\n",
    "#         print(df2a)\n",
    "        df3 = df2a.iloc[:, 0:1].copy()\n",
    "#         print(df3)\n",
    "        df3 = df3.diff() #Subtract each row from next row to give time diff between samples\n",
    "        df3['datetime'] = df3['datetime'].dt.total_seconds() #Convert timediff to total seconds\n",
    "        df3 = df3[~(df3['datetime'] < 5)] #Delete second gaps < 1\n",
    "        df3list = df3.index\n",
    "\n",
    "#----------------------------------------\n",
    "        #Add column to dataframe for WAKE boundary\n",
    "\n",
    "        df2a['wakeboundary'] = df3.datetime\n",
    "\n",
    "        #Add column to dataframe for DAY boundary\n",
    "        df4 = df2a.copy()\n",
    "        df4['dayofweek'] = df4['datetime'].dt.dayofweek\n",
    "        df4['date'] = df4['datetime'].dt.date\n",
    "        df4.drop_duplicates(['date'],keep='first', inplace=True)\n",
    "        df4list = df4.index\n",
    "\n",
    "        df2a['dayboundary'] = df4.date\n",
    "\n",
    "#----------------------------------------\n",
    "        #find gap between each wake boundary and first stroke\n",
    "\n",
    "        #print(df2a.dayboundary.loc[~df2a.dayboundary.isnull()].iloc[2:3])\n",
    "        df2a['peak'] = np.nan\n",
    "        for i in newind:\n",
    "            df2a.loc[i, 'peak'] = 'peak'\n",
    "        df2z = df2a.copy()\n",
    "        df2z.dropna(subset=['wakeboundary','dayboundary','peak'],how='all', inplace=True)\n",
    "\n",
    "        df2z['gap'] = df2z['datetime'].diff().dt.total_seconds()\n",
    "\n",
    "#----------------------------------------\n",
    "        #Draw lines at each day boundary\n",
    "        df4 = df2a.copy()\n",
    "        df4['dayofweek'] = df4['datetime'].dt.dayofweek\n",
    "        df4['date'] = df4['datetime'].dt.date\n",
    "        df4.drop_duplicates(['date'],keep='first', inplace=True)\n",
    "        df4list = df4.index\n",
    "\n",
    "\n",
    "#----------------------------------------\n",
    "        #Throw normal strokes into a table\n",
    "        df2d=df2a.copy()\n",
    "        df2d=df2d.iloc[newind]\n",
    "        df2d['type'] = 'normal'\n",
    "\n",
    "#----------------------------------------\n",
    "        #Join\n",
    "#         print('join')\n",
    "\n",
    "        frames = [df2d] # you can add another table here if you want to add to tables together\n",
    "                        #In the past I was identifying partial strokes in a second table, then joining\n",
    "        result = pd.concat(frames)\n",
    "        result.sort_index(inplace=True)\n",
    "        newindexlist=indexlist.copy()\n",
    "        newindexlist=newindexlist.set_index('peakindex')\n",
    "        result2=pd.concat([result, newindexlist], axis=1)\n",
    "        result2 = result2[pd.notnull(result2['datetime'])] #Get rid of rows where az column is NaN\n",
    "        del result2['inddex']\n",
    "        del result2['inddex2']\n",
    "#         print('join2')\n",
    "#         print(df3list)\n",
    "\n",
    "        dfboundary = df2a.copy()\n",
    "#         print(dfboundary)\n",
    "        dfboundary = dfboundary.iloc[df3list]\n",
    "#         print('join2a1')\n",
    "        dfboundary.drop(dfboundary.columns[1:14], axis=1, inplace=True)\n",
    "#         print('join2a2')\n",
    "\n",
    "        dfboundary['type']='wake/sleep'\n",
    "#         dfboundary.head()\n",
    "#         print('join2b')\n",
    "\n",
    "        frames = [result2,dfboundary]\n",
    "        result2 = pd.concat(frames,sort=False)\n",
    "        result2.sort_index(inplace=True)\n",
    "#         result2 = result2.reindex(result.columns, axis=1)\n",
    "#         print('join3')\n",
    "        del result2['wakeboundary']\n",
    "        del result2['dayboundary']\n",
    "        del result2['peak']\n",
    "        \n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print('***error setting day boundaries for ', filename,e )\n",
    "        print('')\n",
    "        dfSummary = dfSummary.append({'User': User,'File Error':e}, ignore_index=True)\n",
    "        continue  #goto next file\n",
    "\n",
    "    try:\n",
    "        if debug:\n",
    "            print('defining mass and angle for ', filename )     \n",
    "\n",
    "#----------------------------------------        \n",
    "        #Max signal value of each sprayer\n",
    "#         print('calval import')\n",
    "        maxcal1 = float(calval.iloc[calval_index]['calval'])\n",
    "#         print('max cal = ' , maxcal1)\n",
    "\n",
    "        caldf = pd.read_csv(caljoinedfilename)\n",
    "    #     caldf.head()\n",
    "#----------------------------------------\n",
    "        #Sensor Response Curve    \n",
    "\n",
    "\n",
    "        poly_params = np.polyfit(caldf['adj cum secs'], caldf['rate'], 3)    # Fit the data with a 3rd degree polynomial\n",
    "        poly_3 = np.poly1d(poly_params)      # Construct the polynomial\n",
    "\n",
    "        xPoly = np.linspace(0, max(caldf['adj cum secs']), 100)  # Generate 100 x-coordinates from 0 to max(x)\n",
    "        yPoly = poly_3(xPoly)             # Use the polynomial to calculate the y-coordinates\n",
    "\n",
    "#----------------------------------------\n",
    "#         # Plot the results\n",
    "#         plt.plot(caldf['signal'], caldf['mass'], 'o', xPoly, yPoly, '-g')\n",
    "#----------------------------------------\n",
    "\n",
    "        #Generate Mass values for each stroke based on cumulative duration sprayed\n",
    "\n",
    "        #cumulative duration of all sprays\n",
    "        result2['cum_dur']=result2['duration'].cumsum()\n",
    "        #spray rate far each is based on cumulative duration - 1/2 of duration of this stroke\n",
    "            #this will account for any long duration sprays by giving the 'average' rate for that spray\n",
    "        result2['rate'] = poly_3(result2['cum_dur']-(result2['duration']/2))\n",
    "        #mass is rate * time\n",
    "        result2['mass'] = result2['rate']*result2['duration']\n",
    "        # result2['degrees'] = degpoly_3(result2['vhall3'])\n",
    "\n",
    "#----------------------------------------\n",
    "        #Calculate time gap between strokes\n",
    "        result2['time_delta'] = result2['datetime'].diff().astype('timedelta64[ms]')\n",
    "        wakeStrokes=result2['time_delta'].loc[result2['time_delta']<250].count()\n",
    "\n",
    "        result4 = result2.copy()\n",
    "        result4 = result4.dropna(axis=0)\n",
    "#----------------------------------------\n",
    "\n",
    "        totalmass = round(sum(result4.mass))\n",
    "\n",
    "#----------------------------------------        \n",
    "#         maxdegrees = max(result2['degrees'])\n",
    "#         maxdegrees\n",
    "\n",
    "#         result2['angvelocity']=result2['degrees']/result2['fduration']\n",
    "#         result2['SPM']=60/(result2['duration']/(result2['degrees']/maxdegrees)) #Remapping partial stroke to equivalent SPM time\n",
    "#         result2.head()\n",
    "        # add study leg info to data\n",
    "        result2['LegID']=filename[:legChars]\n",
    "        result2['TimeID']=studyTimeID\n",
    "\n",
    "#     except:\n",
    "#         print('***error defining mass for ', filename )\n",
    "#         continue  #goto next file\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print('***error defining mass for ', filename )\n",
    "        print('')\n",
    "        dfSummary = dfSummary.append({'User': User,'File Error':e}, ignore_index=True)\n",
    "        continue  #goto next file\n",
    "\n",
    "    try:\n",
    "        if debug:\n",
    "            print('creating excel for ', filename )\n",
    "\n",
    "#----------------------------------------   \n",
    "\n",
    "#----------------------------------------        \n",
    "#         #TO EXCEL\n",
    "        excelextension = '.xlsx'\n",
    "        exceljoinedfilename = filename+excelextension\n",
    "        writer = ExcelWriter(resultDirXL + exceljoinedfilename) #set file name\n",
    "        result2.to_excel(writer,'Sheet2') #Write df4 data table to sheet 1 of file\n",
    "        writer.save() #save file\n",
    "\n",
    "        dfSummary = dfSummary.append({'User': User,'Start_date':Start_date, 'End_Date':End_Date,\n",
    "                                      'Total_Data_Points':Data_Points,'Strokes_Count':Strokes_Count, \n",
    "                                      'data_errors':dataRateErrors,'Wake_Strokes':wakeStrokes,\n",
    "                                     'Baseline':avgBaseline,'Total_Mass':totalmass}, ignore_index=True)\n",
    "\n",
    "#     except:\n",
    "#         print('***error creating excel for ', filename )\n",
    "#         continue  #goto next file\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print('***error creating excel for ', filename,e )\n",
    "        print('')\n",
    "        dfSummary = dfSummary.append({'User': User,'File Error':e}, ignore_index=True)\n",
    "        continue  #goto next file\n",
    "\n",
    "\n",
    "    print('Completed  ', filename )\n",
    "    print('')\n",
    "    print('time for this file ',timeit.default_timer()-fileStartTime)\n",
    "    print('')\n",
    "\n",
    "if not skip:\n",
    "    excelextension = '.xlsx'\n",
    "    exceljoinedfilename = Summaryfilename +filename[:legChars]+excelextension\n",
    "    writer = ExcelWriter(resultDirChart + exceljoinedfilename) #set file name\n",
    "    dfSummary.to_excel(writer,'Sheet2') #Write summary data table to sheet 1 of file\n",
    "    writer.save() #save file\n",
    "        \n",
    "print('All Files complete')\n",
    "print('time for all files',timeit.default_timer()-totalStartTime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      User              Start_date                End_Date Total_Data_Points  \\\n",
      "0   CC-146 2021-03-22 07:15:31.019 2021-05-11 07:30:29.547            177822   \n",
      "1   CC-147 2021-03-20 12:50:33.019 2021-05-11 07:38:23.949            149222   \n",
      "2   CC-148 2021-03-19 11:35:18.028 2021-05-11 08:13:14.028            157022   \n",
      "3   CC-149 2021-03-20 12:25:37.028 2021-05-12 06:50:06.795            232070   \n",
      "4   CC-150 2021-03-19 19:37:13.028 2021-05-11 08:53:03.189            175126   \n",
      "5   CC-151 2021-03-19 17:24:34.018 2021-05-12 07:13:48.488            168014   \n",
      "6   CC-152 2021-03-20 09:38:41.028 2021-05-11 10:23:37.569            210182   \n",
      "7   CC-153 2021-03-19 10:59:03.028 2021-05-11 10:28:07.098            391958   \n",
      "8   CC-154 2021-03-20 07:57:10.028 2021-05-11 12:13:14.797            482254   \n",
      "9   CC-155 2021-03-20 09:27:48.028 2021-05-12 06:55:56.858            192190   \n",
      "10  CC-156 2021-03-20 08:30:10.028 2021-05-12 06:47:33.220            165902   \n",
      "11  CC-157 2021-03-20 08:44:53.028 2021-05-12 06:09:49.759            297166   \n",
      "12  CC-158 2021-03-20 01:29:54.028 2021-05-12 07:18:59.396            235278   \n",
      "13  CC-159 2021-03-20 08:49:44.028 2021-05-12 07:30:41.974            155582   \n",
      "14  CC-160 2021-03-19 12:33:47.028 2021-05-12 07:37:54.136            278926   \n",
      "\n",
      "   Strokes_Count data_errors Wake_Strokes  Baseline  Total_Mass  \n",
      "0             20           0            0   0.02461       148.0  \n",
      "1             32           0            0   0.00274        21.0  \n",
      "2             27           1            5   0.01343        63.0  \n",
      "3            140           1            7   0.04938       234.0  \n",
      "4             15           0            2   0.00360        46.0  \n",
      "5             69           0            1   0.02536       142.0  \n",
      "6             30           0            2   0.00631        68.0  \n",
      "7            102           1            3   0.01510       114.0  \n",
      "8            157           1            7   0.01422       230.0  \n",
      "9             16           0            3   0.00210        15.0  \n",
      "10            25           2            2   0.00501        60.0  \n",
      "11           222           1            4   0.05898       190.0  \n",
      "12           121           2           15   0.01428       136.0  \n",
      "13            26           0            1   0.00660        41.0  \n",
      "14            62           0            0   0.00746        66.0  \n"
     ]
    }
   ],
   "source": [
    "print(dfSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "647px",
    "left": "910px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
